% conceitos basicos
Neste capítulo faremos uma apresentação dos conceitos básicos
necessários para o entendimento e desenvolvimento deste trabalho. Na
Seção~\ref{sec:defin} mostraremos as formalizações usadas pelos
problemas de rearranjos de genomas. As
seções~\ref{sec:rev},~\ref{sec:trans} e~\ref{sec:rev_trans} descrevem,
respectivamente, os problemas de ordenação por reversões, ordenação por
transposições e ordenação por reversões e transposições. A
Seção~\ref{sec:def_cp} explica o conceito de \pr{}.

\section{Definições}
\label{sec:defin}
Para todos os problemas usamos as seguintes formalizações.

\paragraph{Permutação.} Um genoma é representado por uma $n$-tupla de
genes, e quando não há genes repetidos, essa $n$-tupla é chamada de
permutação. Uma permutação é representada como $\pi =
(\pi_{1}~\pi_{2}~\ldots~\pi_{n})$, para $\pi_{i} \in \mathbb{N}$, $0 <
\pi_{i} \leq n$ e $i \neq j \leftrightarrow \pi_{i} \neq \pi_{j}$. A
permutação identidade é representada como $\iota = (1~2~3~\ldots~n)$.
Como exemplo, usaremos como a permutação $\pi = (4~7~3~6~2~5~1)$.

\paragraph{Eventos de rearranjo.} Os eventos de rearranjo tratados neste
trabalho são os eventos de transposição e reversão ocorrendo
isoladamente e ocorrendo de forma conjunta. Os eventos são representados
por $\rho$ e são aplicados a $\pi$ de uma maneira específica. Por
exemplo, uma reversão $\rho(1, 3)$ aplicada a permutação $\pi =
(4~7~3~6~2~5~1)$ será representada por $\pi\rho = (3~7~4~6~2~5~1)$, e
uma transposição $\rho(2,4,6)$ aplicada a permutação $\pi =
(4~7~3~6~2~5~1)$ será representada por $\pi\rho = (4~6~2~7~3~5~1)$.

\section{Ordenação por Reversões}
\label{sec:rev}
Um evento de reversão ocorre quando um bloco do genoma é invertido. Uma
reversão $\rho(i, j)$, para $1 \leq i < j \leq n$, aplicada ao genoma
$\pi = (\pi_{1}~\pi_{2}~\ldots~\pi_{n})$ gera a permutação $\pi\rho =
(\pi_{1}~\ldots~\pi_{i-1}~\pi_{j}~\pi_{j-1}~\ldots~\pi_{i+1}~\pi_{i}$
$\pi_{j+1}~\ldots~\pi_{n})$, caso a orientação de $\pi$ não seja
conhecida (Figura~\ref{fig:rev_nao_orientada}), e $\pi\rho =
(+\pi_{1}~\ldots~+\pi_{i-1}~-\pi_{j}~-\pi_{j-1}~\ldots~-\pi_{i+1}$
$-\pi_{i}~+\pi_{j+1}~\ldots~+\pi_{n})$, caso a orientação de $\pi$ seja
conhecida (Figura~\ref{fig:rev_orientada}).

\begin{figure}[h]
  \centering
  \includegraphics{images/rev_nao_orientada-color.png} 
  \caption{Reversão em uma permutação não orientada.}
  \label{fig:rev_nao_orientada}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics{images/rev_orientada-color.png}
  \caption{Reversão em uma permutação orientada.}
  \label{fig:rev_orientada}
\end{figure}

O problema da distância de reversão é encontrar o número mínimo de
reversões necessárias para transformar um genoma em outro. A distância
de reversão entre duas permutações $\pi$ e $\sigma$ é representada por
$d_{r}(\pi,\sigma)$. Note que a distância de reversão entre $\pi$ e
$\sigma$ é igual à distância de reversão entre $\sigma^{-1} \pi$ e
$\iota$. Então, sem perda de generalidade, podemos dizer que o problema
da distância de reversão é equivalente ao problema de ordenação por
reversões, que é a distância de reversão entre a permutação $\pi$ e a
permutação identidade $\iota$, denotado por $d_{r}(\pi)$.

Em um estudo inicial sobre este problema, Bafna e
Pevzner~\cite{BafnaPevzner*1996} apresentaram um algoritmo de
aproximação com razão $1.5$ quando a orientação de genes é conhecida e
$1.75$, caso contrário.

Conhecer a orientação dos genes em um genoma é um fator importante no
problema de reversão, pois existem algoritmos polinomiais para o caso em
que a orientação é conhecida. No caso em que não se conhece a orientação
dos genes, o problema de encontrar a distância de reversão pertence à
classe dos problemas NP-Difíceis~\cite{Caprara*1997}.

O primeiro algoritmo polinomial para o problema de reversão com
orientação conhecida foi criado por Hannenhalli e
Pevzner~\cite{HannenhalliPevzner*1995} que fez uso de várias operações
aplicadas a uma estrutura intermediária conhecida como grafo de \bkp{}.
A estratégia usada por Hannenhalli e Pevzner foi simplificada no
trabalho de Bergeron~\cite{Bergeron*2005}. Atualmente já existe um
algoritmo com complexidade sub quadrática~\cite{TannierSagot*2004} e,
quando apenas a distância é necessária, um algoritmo linear pode ser
usado~\cite{BaderMoretYan*2001}.

Um resultado importante obtido por Meidanis, Walter e
Dias~\cite{MeidanisWalterDias*2000} mostrou que toda teoria sobre
reversões desenvolvida para genomas lineares pode ser adaptada
facilmente para genomas circulares, que são comuns em seres como
bactérias e plantas, por exemplo \textit{Brassica oleracea}.

Quando a orientação dos genes não é conhecida, existem algoritmos de
aproximação que seguiram a ideia do trabalho de Bafna e Pevzner citado
anteriormente como, por exemplo, o algoritmo implementado por Berman,
Hannenhalli e Karpinski~\cite{BermanHannenhalliKarpinski*2002} com razão
de aproximação de $1.375$.

O conceito de grafo de \bkp{} foi introduzido no trabalho de Bafna e
Pevzner~\cite{BafnaPevzner*1996}. Inicialmente a permutação $\pi$ é
estendida adicionando o elemento $\pi_{0} = 0$ e $\pi_{n+1} = n+1$. Dois
elementos consecutivos $\pi_{i}$ e $\pi_{i+1}$, $0 \le i \le n$, são
\textit{adjacentes} quando $|\pi_{i} - \pi_{i+1}| = 1$, e são
\estr{breakpoints} caso contrário. Define-se um grafo de arestas
coloridas $G(\pi)$ com $n + 2$ vértices \{$\pi_{0}$,
$\pi_{1}$,~$\ldots$~, $\pi_{n}$, $\pi_{n + 1}$\}. Unimos os vértices
$\pi_{i}$ e $\pi_{j}$ com uma aresta preta se $(\pi_{i}, \pi_{j})$ for
um \estr{breakpoint} na permutação $\pi$. Unimos os vértices $\pi_{i}$ e
$\pi_{j}$ com uma aresta cinza se $|\pi_{i} - \pi_{j}| = 1$ e $\pi_{i}$,
$\pi_{j}$ não são consecutivos em $\pi$. Denotamos por $b_r(\pi)$ o
número de \bkp{} existentes em $\pi$ com relação a permutação identidade
$\iota$. A Figura~\ref{fig:rev_grafo_bkp} mostra o grafo de \bkp{} da
permutação $\pi = (4~7~3~6~2~5~1)$. Neste caso o número de
\textit{breakpoints} é $b_r(\pi) = 8$.

\begin{figure}[h]
  \centering 
  \includegraphics[scale=0.6]{images/rev_grafo_bkp.png} 
  \caption{Grafo de \bkp{} da permutação $\pi = (4~7~3~6~2~5~1)$.}
  \label{fig:rev_grafo_bkp}
\end{figure}

Usando o conceito de \bkp{}, temos que uma reversão atua em dois pontos
em uma permutação e, portanto, pode reduzir~\footnote{Uma reversão pode
aumentar o número de \bkp{}, mas queremos a reduzir o seu número
para diminuir a diferença entre o número de \bkp{} da permutação
$\pi$ e o número de \bkp{} da permutação identidade $\iota$
($b_r(\iota) = 0$).} o número de \bkp{} em pelo menos um e no máximo
dois~\cite{BafnaPevzner*1996}, levando ao
Teorema~\ref{teo:rev_bkp_bound}.

\begin{teo}
\label{teo:rev_bkp_bound}
Para qualquer permutação $\pi$, 
\[\frac{1}{2} b_r(\pi) \leq d_r(\pi) \leq
  b_r(\pi).
\]
\end{teo}

Um ciclo em $G(\pi)$ é chamado de \textit{alternado} se as cores de duas
arestas consecutivas são diferentes ao longo do ciclo. Assim dizemos que
todos os ciclos pertencentes ao grafo serão ciclos alternados. O
\textit{comprimento} de um ciclo é a sua quantidade de arestas pretas.
Um $k$-ciclo é um ciclo que contém $k$ arestas pretas. Um \textit{ciclo
longo} é um ciclo de comprimento maior que dois.

Observe que $G(\pi)$ pode ser decomposto em ciclos de arestas disjuntas,
pois cada vértice tem o mesmo número de arestas incidentes cinzas e
pretas. Logo existem diversas maneiras de realizar a decomposição de
ciclos em $G(\pi)$. A Figura~\ref{fig:rev_grafo_bkp_dec2cic} mostra um
exemplo de decomposição em ciclos para o grafo de \bkp{} da permutação
$\pi = (4~7~3~6~2~5~1)$.

\begin{figure}[h]
  \centering 
  \begin{tabular}{ccc} 
  \includegraphics[scale=0.6]{images/rev_grafo_bkp_dec2cic-1.png}
  & ~~~~
  & \includegraphics[scale=0.6]{images/rev_grafo_bkp_dec2cic-2.png} 
  \end{tabular} 
  \caption{Exemplo de decomposição em ciclos de arestas disjuntas para
  o grafo de \bkp{} da permutação $\pi = (4~7~3~6~2~5~1)$.}
  \label{fig:rev_grafo_bkp_dec2cic}
\end{figure}

Uma reversão atua em duas arestas pretas de $G(\pi)$, se as arestas
representam os \bkp{} que são separados pela operação de
reversão~\cite{Christie*1998}. O Teorema~\ref{teo:rev_cic_bound},
demonstrado no trabalho de Christie~\cite{Christie*1998}, fornece novos
limites para a distância de reversão usando a quantidade de $2$-ciclos,
além dos breakpoints, na máxima decomposição em ciclos de $G(\pi)$.

\begin{teo}
\label{teo:rev_cic_bound}
Se $c_{2}(\pi)$ é o número mínimo de $2$-ciclos em qualquer máxima
decomposição em ciclos de $G(\pi)$ então: 
\[
\frac{2}{3} b_r(\pi)
- \frac{1}{3} c_{2}(\pi) \leq d_r(\pi) \leq b_r(\pi) - \frac{1}{2}
c_{2}(\pi).
\]
\end{teo}

\section{Ordenação por Transposições}
\label{sec:trans}
% transposicoes
Um evento de transposição ocorre quando dois blocos adjacentes no genoma
trocam de posição. Uma transposição $\rho(i, j, k)$, para $1 \leq i < j
< k \leq n + 1$, aplicada ao genoma $\pi =
(\pi_{1}~\pi_{2}~\ldots~\pi_{n})$ gera a permutação $\pi\rho =
(\pi_{1}~\ldots~\pi_{i-1}~\pi_{j}~\ldots~\pi_{k-1}~\pi_{i}~\ldots$
$\pi_{j-1}~\pi_{k}~\ldots~\pi_{n})$ (Figura~\ref{fig:transposition}).

\begin{figure}[h]
  \centering
  \includegraphics{images/transposition-color.png} 
  \caption{Transposição aplicada em uma permutação.}
  \label{fig:transposition}
\end{figure}

O problema da distância de transposição é encontrar o número mínimo de
transposições necessárias para transformar um genoma em outro. A
distância de transposição entre duas permutações $\pi$ e $\sigma$ é
representada por $d_{t}(\pi, \sigma)$. Note que a distância de
transposição entre $\pi$ e $\sigma$ é igual à distância de transposição
entre $\sigma^{-1} \pi$ e $\iota$. Então, sem perda de generalidade,
podemos dizer que o problema da distância de transposição é equivalente
ao problema de ordenação por transposições, que é a distância de
transposição entre a permutação $\pi$ e a permutação identidade $\iota$,
denotado por $d_{t}(\pi)$.

Este problema foi estudado por Bafna e Pevzner~\cite{BafnaPevzner*1998},
que apresentaram um algoritmo capaz de fornecer uma resposta aproximada
na razão de $1.5$, além de derivar um importante limite inferior para o
problema. Introduziram também o conceito de \bkp{} em eventos de
transposições, elementos adjacentes em um genoma, mas não no outro, e o
conceito de grafo de ciclos, ambos ferramentas importantes utilizadas
para encontrar limitantes para o problema. Foram apresentadas várias
questões em aberto, como verificar a complexidade do problema da
distância de transposição e o diâmetro, que é a maior distância possível
entre duas permutações de tamanho $n$. O problema do diâmetro foi
estudado por Meidanis, Walter e Dias~\cite{MeidanisWalterDias*1997}.

A complexidade deste problema ficou em aberto por um longo tempo. O
trabalho de Bulteau, Fertin e Rusu~\cite{BulteauFertinRusu*2010}
apresentou a prova de que o problema de ordenação por transposição
pertence a classe dos problemas NP-Difíceis. Elias e
Hartman~\cite{EliasHartman*2006} apresentaram um algoritmo de
aproximação na razão de $1.375$. O trabalho de
Labarre~\cite{Labarre*2006} apresentou novos limitantes, além de definir
classes de permutações em que a distância de transposição pode ser
calculada em tempo e espaço lineares.

No problema de ordenação por transposições, um \textit{breakpoint} é um
par $(\pi_{i}, \pi_{i+1})$ tal que $\pi_{i+1} \neq \pi_{i} + 1$.
Denota-se por $b_{t}(\pi)$ como sendo o número de \textit{breakpoints}
na permutação $\pi$. Sabemos que uma transposição atua em três pontos de
uma permutação, logo, pode reduzir~\footnote{Assim como no caso de
reversão, uma transposição pode aumentar o número de
\textit{breakpoints}, mas queremos reduzir o seu número para
diminuir a diferença entre o número de \textit{breakpoints} da
permutação $\pi$ e o número de \textit{breakpoints} da permutação
identidade $\iota$ ($b_t(\iota) = 0$).} o número de \textit{breakpoints} 
em pelo menos um e no máximo três~\cite{BafnaPevzner*1998}, levando ao
Teorema~\ref{teo:trans_br_bound}.

\begin{teo}
  \label{teo:trans_br_bound}
  Para qualquer permutação $\pi$, 
  \[
  \frac{1}{3}b_t(\pi) \leq d_t(\pi) \leq b_t(\pi).
  \]
\end{teo}

O conceito de grafo de ciclos foi introduzido por Bafna e
Pevzner~\cite{BafnaPevzner*1998} e foi usado para obter limitantes
melhores para o problema. Um grafo direcionado com arestas coloridas,
denotado por $G(\pi)$, é chamado de grafo de ciclos da permutação $\pi$
se possui um conjunto de vértices $\{0,~1,~\ldots,~n+1\}$ e seu conjunto
de arestas é definido como para todo $1 \leq i \leq n+1$, arestas cinzas
são direcionadas de $i-1$ para $i$ e arestas pretas de $\pi_{i}$ para
$\pi_{i-1}$. A Figura~\ref{fig:trans_cycle_graph} mostra o grafo de
ciclos para a permutação $\pi = (4~7~3~6~2~5~1)$.

\begin{figure}[h]
  \centering 
  \includegraphics[scale=0.6]{images/trans_cycle_graph.png} 
  \caption{Grafo de ciclos para a permutação $\pi = (4~7~3~6~2~5~1)$.}
  \label{fig:trans_cycle_graph}
\end{figure}

De forma similar ao problema de ordenação por reversões, um ciclo de
$G(\pi)$ é chamado de \textit{alternado} se ele for um ciclo direcionado
com arestas de cores alternadas. Para todo vértice de $G(\pi)$ toda
aresta chegando é unicamente pareada com uma aresta saindo de cor
diferente. Isto implica que existe uma decomposição única de ciclos
alternados do conjunto de arestas de $G(\pi)$. A seguir o termo ciclo é
usado no lugar de ciclos alternados e usamos o termo $k$-ciclo para
definir um ciclo alternado de tamanho $2k$, $k$-ciclo é longo se $k >
2$, e curto caso contrário. A Figura~\ref{fig:tra_grafo_bkp_dec} mostra
um exemplo de decomposição em ciclos para o grafo de ciclos da
permutação $\pi = (4~7~3~6~2~5~1)$.

\begin{figure}[h]
  \centering 
  \includegraphics[scale=0.6]{images/trans_cycle_graph_dec-1.png}
  \includegraphics[scale=0.6]{images/trans_cycle_graph_dec-2.png} 
  \caption{Exemplo de decomposição em ciclos de arestas disjuntas para
  o grafo de ciclos da permutação $\pi = (4~7~3~6~2~5~1)$.}
  \label{fig:tra_grafo_bkp_dec}
\end{figure}

Para melhorar o limitante, Bafna e Pevzner~\cite{BafnaPevzner*1998}
estudaram separadamente os ciclos pares e ímpares. Um ciclo é impar se
possui um número ímpar de arestas pretas e par caso contrário. Seja
$c_{\text{ímpar}}(\pi)$ o número de ciclos ímpares de $G(\pi)$, para uma
permutação $\pi$, e $\Delta c_{\text{ímpar}} (\rho) = c_{\text{ímpar}}
(\pi \rho) - c_{\text{ímpar}} (\pi)$ a mudança no número de ciclos
ímpares devido a transposição $\rho$, temos que $\Delta c_{\text{ímpar}}
\in \{2, 0, -2\}$ gerando o resultado do
Teorema~\ref{teo:trans_cg_bound}. Note que a permutação identidade
possui $c_{\text{ímpar}}(\iota) = n + 1$, então se a cada transposição
for possível aumentar o número de ciclos ímpares da permutação $\pi$
ficaremos mais próximos de transformá-la na permutação identidade
$\iota$.

\begin{teo} 
  \label{teo:trans_cg_bound} 
  Para qualquer permutação $\pi$, 
  \[ 
  \frac{1}{2}(n + 1 - c_{\text{ímpar}}(\pi)) \leq d_t(\pi) \leq \frac{3}{4} (n
  + 1 - c_{\text{ímpar}}(\pi)).
  \]
\end{teo}

\section{Ordenação por Reversões e Transposições}
\label{sec:rev_trans}
% reversoes e transposicoes
Na natureza um genoma não sofre apenas eventos de reversão ou de
transposição, ele está exposto a diversos eventos mutacionais
diferentes. Para esta situação, iremos estudar o caso onde os eventos de
reversão e transposição ocorrem simultaneamente em um genoma.

O problema da distância de reversão e transposição é encontrar o número
mínimo de reversões e transposições necessárias para transformar um
genoma em outro. A distância de reversão e transposição entre duas
permutações $\pi$ e $\sigma$ é representada por $d_{rt}(\pi, \sigma)$.
De forma similar ao caso em que os eventos ocorrem individualmente,
podemos dizer, sem perda de generalidade, que o problema da distância de
reversão e transposição é equivalente ao problema de ordenação por
reversões e transposições, que é a distância de reversão e transposição
entre a permutação $\pi$ e a permutação identidade $\iota$, denotado por
$d_{rt}(\pi)$.

Este problema foi estudado por Hannenhalli e
coautores~\cite{HannenhalliChappeyKooninPevzner*1995}, que analisaram a
evolução de genomas por diferentes tipos de eventos, em especial
reversões e transposições. 

Em 1998, Walter, Dias e Meidanis \cite{WalterDiasMeidanis*1998}
apresentaram um algoritmo de aproximação para a distância de reversão e
transposição, além de limitantes para o diâmetro de reversão e
transposição em permutações orientadas que foram posteriormente
melhorados \cite{MeidanisWalterDias*2002}.

No trabalho de Gu, Peng e Sudborough~\cite{GuPengSudbourough*1999} é
apresentado um algoritmo $2$-aproximado para computar a distância entre
dois genomas com a orientação dos genes conhecida usando a operação de
reversão e transposição simultaneamente.

\section{Programação por Restrições}
\label{sec:def_cp}
Programação por Restrições é um paradigma de programação que usa
restrições para estabelecer as relações entre as variáveis.
Diferentemente da programação imperativa, as restrições não usam passos
para executar, mas usam as propriedades da solução a ser encontrada.
Resumidamente, uma restrição sobre uma sequência de variáveis é a
relação entre seus domínios. Pode ser vista como um requisito que diz
quais combinações de valores dos domínios das variáveis serão admitidas.
Um problema é então simplificado usando entidades e seus
relacionamentos. As entidades de um modelo de programação por restrição
são chamadas de variáveis e os relacionamentos de restrições.

\begin{defin}
\label{defin:csp}
Um modelo de programação por restrições $P$ é formado por:
\begin{itemize}
  \item{Um conjunto de variáveis $X = \{x_{1}, \ldots, x_{n}\}$, com
  seus respectivos domínios $D_{1}, \ldots, D_{n}$.}

  \item{Um conjunto finito de restrições $C$, cada um sobre uma
  subsequência de $X$.}
\end{itemize}
\end{defin}

Então, o modelo pode ser escrito como $P = \langle C; x_{1} \in
D_{1}, \ldots, x_{n} \in D_{n} \rangle$. A solução é a associação
$\{(x_{1}, d_{1}), \ldots, (x_{n}, d_{n})\}$, onde $d_{i} \in D_{i}$,
que satisfaz todas as restrições em $C$. Um modelo $P$ é
chamado \textit{consistente} (ou \textit{viável}) se possuir pelo
menos uma solução, caso contrário, é chamado de \textit{inconsistente}
(ou \textit{inviável}).

Os modelos que usam a teoria do Problema de Satisfação de Restrições
(CSP\footnote{Do inglês \estr{Constraint Satisfaction Problems}.}) são
descritos conforme a Definição~\ref{defin:csp} acima. Para exemplificar
os modelos que usam a teoria CSP, iremos usar o problema das $n$
rainhas, que é um dos problemas mais conhecido baseado na teoria CSP.

O problema das $n$ rainhas consiste em posicionar as rainhas em um
tabuleiro $n \times n$, onde $n \geq 3$, de modo que nenhuma rainha seja
atacada por outra. A Figura~\ref{fig:n-queens} mostra uma das soluções
para o problema quando temos $n = 8$.

\begin{figure}[h]
  \centering 
  \includegraphics[scale=1]{images/n-queens.png} 
  \caption{Uma das soluções para o problema das 8 rainhas.}
  \label{fig:n-queens}
\end{figure}

Uma das possíveis representações usando a teoria CSP para o problema usa
$n$ variáveis, $X = \{x_{1}, \ldots, x_{n}\}$, onde $1 \leq x_{i} \leq
n$ para todo $1 \leq i \leq n$. Então, uma variável $x_{i}$ representa a
posição da rainha posicionada na $i$-ésima coluna do tabuleiro. Por
exemplo, a solução mostrada na figura~\ref{fig:n-queens} corresponde aos
valores $X = \{6, 4, 7, 1, 8, 2, 5, 3\}$, sendo que a primeira rainha da
esquerda foi posicionada na sexta linha de baixo para cima, a segunda
rainha foi posicionada na quarta linha, e segue desta maneira para as
outras rainhas.

O conjunto de restrições pode ser formulado usando as seguintes
desigualdades para $1 \leq i \leq n - 1$ e $i + 1 \leq j \leq n$:

\begin{itemize}

    \item{$x_i \neq x_j$ (Não permite duas rainhas na mesma linha),}

    \item{$x_i - x_j \neq i - j$ (Não permite duas rainhas na diagonal
        ascendente),}

    \item{$x_i - x_j \neq j - i$ (Não permite duas rainhas na diagonal
        descendente).}

\end{itemize}

Os modelos que são baseados na teoria do Problema de Otimização com
Restrições (COP\footnote{Do inglês \estr{Constraint Optimization
Problems}.}) possuem o objetivo de encontrar a melhor solução de um
conjunto de restrições, usando uma função de custo, ou seja,
considerando um modelo da teoria CSP, $P_{csp} = \langle C; x_{1} \in
D_{1}, \ldots, x_{n} \in D_{n} \rangle$, e uma função de custo, $custo:
D_{1} \times \ldots \times D_{n} \to R$, queremos encontrar a solução
$\{(x_{1}, d_{1}), \ldots, (x_{n}, d_{n})\}$ de $P_{csp}$, para qual o
valor $custo(d_{1}, \ldots, d_{n})$ seja ótimo. Logo, os modelos
baseados na teoria COP são representados como $P_{cop} = \langle
P_{csp}, custo \rangle$. Para exemplificar os modelos que usam a teoria
COP, iremos usar o problema da mochila, um problema bastante famoso na
área de otimização combinatória.

O problema da mochila é preencher a mochila com um conjunto de objetos
cujo valor total seja máximo, sem ultrapassar o peso total da mochila.
Formalizando, nós temos $n$ objetos com pesos $A = \{a_1, \ldots, a_n\}$
e valores $B = \{b_1, \ldots, b_n\}$ e o peso máximo que a mochila
suporta $w$. Usaremos o conjunto de variáveis binárias $X = \{x_1,
\ldots, x_n\}$, que serão usadas para determinar se o objeto $i$ será
colocado ou não dentro da mochila, sendo que $x_i = 1$ caso o objeto é
colocado na mochila, e $x_i = 0$ caso contrário.

A restrição do problema é se a mochila suporta o peso total dos
objetos colocados:

\[
    \sum_{i=1}^{n} a_i \cdot x_i \leq w
\]

Nós então procuramos a solução para esta restrição, que será a seguinte 
soma:

\[
    \sum_{i=1}^{n} b_i \cdot x_i
\]

Como o modelo é baseado na teoria COP, precisamos otimizar a solução.
Logo, a função de custo será:

\[
    \max \sum_{i=1}^{n} b_i \cdot x_i
\]

Nesta dissertação, usamos duas abordagens diferentes para a criação dos
modelos, uma baseada na teoria do Problema de Satisfação de Restrições,
e outra baseada na teoria do Problema de Otimização com Restrições.
Recomendamos a leitura de Apt~\cite{Apt*2003}, Apt e
Wallace~\cite{AptWallace*2007} e Marriot e Stuckey~\cite{Marriott*1998}
para um aprofundamento maior sobre \pr{}.

\paragraph{Métodos de Solução dos Problemas de \PR{}.}
Para encontrar soluções em um modelo de \pr{}, utiliza-se algoritmos de
propagação de restrições, cujo objetivo é reduzir o espaço de busca nos
domínios das variáveis. Esses algoritmos fazem a redução do problema em
outro mais simples de solucionar. Para lidar com essa situação, usamos a
Definição \ref{defin:cp_eq}.

\begin{defin}
\label{defin:cp_eq}
    Considere dois modelos de \pr{} $P_{1}$ e $P_{2}$ e uma sequência
    $X$ das suas variáveis comuns ($X \subset X_{1}$ e $X \subset
    X_{2}$, onde $X_{1}$ e $X_{2}$ são, respectivamente, sequências das
    variáveis de $P_{1}$ e $P_{2}$). Então, $P_{1}$ e $P_{2}$ são
    equivalentes em relação a $X$, se:

    \begin{itemize}

        \item{para toda solução $d$ em $P_{1}$, existe uma solução em
            $P_{2}$ que coincide com $d$ nas variáveis em $X$.}

        \item{para toda solução $e$ em $P_{2}$, existe uma solução em
            $P_{1}$ que coincide com $e$ nas variáveis em $X$.}

    \end{itemize}

\end{defin}

Mas, em muitos casos, os modelos de \pr{} possuem restrições que não se
ligam às restrições simples ou são um grupo de restrições de diversos
tipos. Então, nestes casos utiliza-se métodos baseados em buscas sobre
os domínios das variáveis. A seguir, listaremos alguns métodos de buscas
mais utilizados.

\begin{itemize}

    \item{\textbf{Busca Local:} Classe de algoritmo, usada para os
        modelos que usam as teorias CSP e COP, que possui o objetivo de
        encontrar uma solução utilizando uma atribuição inicial definida
        sobre as variáveis (chamada neste contexto de \textit{estado}) e
        tenta melhorar sua \textit{qualidade} a cada iteração, fazendo
        pequenas mudanças locais, chamadas de \textit{movimento}. A
        qualidade do estado é definida por uma função de custo (Ex:
        Número de restrições violadas pelo estado.  Então a qualidade de
        uma solução será 0.).

        O conceito principal de uma busca local é a utilização de
        \textit{vizinhança}, que tem o objetivo de associar para cada
        estado um conjunto de estados, chamados de \textit{vizinhos}.
        Então, a busca local começa do estado inicial, entra em um
        \estr{loop}, no qual realiza um movimento de um estado para seu
        vizinho. O estado final é ou uma solução para o modelo, ou um estado
        de parada, indicando que nenhuma solução foi encontrada até este
        estado.}

    \item{\textbf{Busca Top-Down:} Método de busca mais usado em
        modelos que usam a teoria CSP\@. Utiliza a estratégia de
        \estr{branching} em conjunto aos algoritmos de propagação de
        restrições. O \estr{branching} possibilita a divisão de um
        modelo CSP em dois ou mais CSPs, sendo que a união destes é
        equivalente ao problema inicial. A propagação de restrição
        permite transformar um dado modelo CSP em um equivalente mais
        simples. A Busca top-down alterna os métodos de \estr{branching}
        e de propagação de algoritmos, usando uma árvore que é chamada
        de \textit{árvore de busca}. As folhas desta árvore são ou CSPs
        inconsistentes ou uma solução para um dos CSPs gerados pela
        técnica. A Figura~\ref{fig:searchtree} apresenta um exemplo de
        uma árvore de busca, note que a árvore é gerada
        \estr{on-the-fly}\footnote{Gerada no momento da execução do
        modelo.}.

        \begin{figure}[h]
            \centering 
            \includegraphics{images/searchtree.png}
            \caption{Exemplo de árvore de busca para um modelo CSP.}
            \label{fig:searchtree}
        \end{figure}

        O procedimento padrão de uma busca top-down é
        o \estr{backtracking}. Ele inicia a busca pelo nó raiz da árvore e
        segue para o primeiro nó descendente. O processo continua até que
        uma folha é encontrada, neste caso, ele retorna para o nó ancestral
        mais próximo que possua outro nó descendente, e então o processo
        recomeça. Se o controle voltou para o nó raiz e todos os
        descendentes foram visitados, o processo termina.

        Um exemplo de \estr{branching} é a técnica conhecida
        como \estr{labelling}, que divide um domínio (finito) de uma
        variável em domínios unitários, correspondendo a uma busca
        sistemática de todos os valores de uma determinada variável. Uma
        forma de propagação de restrições, combinada com o \estr{branching},
        é aplicada ao longo da árvore, removendo valores dos domínios das
        variáveis que não participam de nenhuma solução.}

    \item{\textbf{Busca Branch and Bound:} Método de busca mais usado em
        modelos que usam a teoria COP\@. Utiliza a técnica de
        \textit{backtracking} levando em conta a função de custo.
        Suponha que o objetivo do problema é encontrar uma solução com o
        valor mínimo para a função de custo. Durante a busca usamos uma
        variável \textit{bound} para guardar o \textit{melhor valor
        encontrado}. O valor inicial desta variável é $\infty$. Então a
        cada vez que uma solução menor é encontrada, este valor é
        guardado em \textit{bound}.

        Há diversas variações no algoritmo de branch and bound, mas um
        ponto importante a ser considerado é o que fazer após encontrar
        uma solução com melhor custo. O método mais simples é reiniciar
        o processamento com a variável \textit{bound} inicializada com o
        novo valor para o custo.

        Uma alternativa é continuar a busca por soluções melhores sem
        reiniciar o processamento. Neste caso a restrição $custo(x_1,
        \ldots, x_n) < \textit{bound}$ é usada e a cada vez que
        encontramos uma solução com custo melhor, esta solução é
        adicionada dinamicamente à restrição $custo(x_1, \ldots, x_n) <
        \textit{bound}$. A propagação de restrição é acionada por esta
        restrição, levando à poda da árvore de busca ao identificar que
        as soluções a partir de um determinado nó não pode gerar uma
        solução com custo melhor que o atual, mantido pela variável
        \textit{bound}.  A figura~\ref{fig:bbsearchtree} mostra o estado
        de uma árvore de busca usando o método branch and bound. As
        linhas pontilhadas representam as partes ignoradas durante a
        busca por não gerar uma solução melhor.

        \begin{figure}[h]
            \centering 
            \includegraphics{images/bbsearchtree.png}
            \caption{Exemplo de árvore de busca usando método branch and
            bound.} 
            \label{fig:bbsearchtree}
        \end{figure}}

\end{itemize}
